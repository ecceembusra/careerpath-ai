"""
CareerPath AI â€” CV â†”ï¸ Ä°ÅŸ Ä°lanÄ± EÅŸleÅŸme (Streamlit)
---------------------------------------------------
Bu uygulama, kullanÄ±cÄ±nÄ±n CV'si ile seÃ§ilen iÅŸ ilanÄ± arasÄ±ndaki uyumu analiz eder:
1) Metin Ã¶n-iÅŸleme ve normalizasyon
2) Skill Ã§Ä±karÄ±mÄ± (lexicon + alias normalizasyonu)
3) ÃœÃ§ bileÅŸenli skor:
   - %50 Skill Coverage   : JD'de istenen skill'lerin CV'de bulunma oranÄ±
   - %30 Text Similarity  : TF-IDF + Cosine benzerliÄŸi
   - %20 Keyword Overlap  : GÃ¶rev/anahtar sÃ¶zcÃ¼k ortaklÄ±ÄŸÄ±
4) Ã‡Ä±ktÄ±lar: EÅŸleÅŸme skoru, gÃ¼Ã§lÃ¼/geliÅŸtirilecek alanlar, uzun cover letter
"""

# ============== 1) KÃœTÃœPHANELER ==============
import io, re, textwrap, string
import streamlit as st
from PyPDF2 import PdfReader
from docx import Document
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


# ============== 2) STREAMLIT SAYFA AYARI ==============
st.set_page_config(page_title="CareerPath AI", page_icon="ğŸ’¼", layout="wide")
st.title("CareerPath AI â€” CV â†”ï¸ Ä°ÅŸ Ä°lanÄ± EÅŸleÅŸme")


# ============== 3) SÃ–ZLÃœKLER (SKILL & KEYWORD) ==============
# - SKILL_LEXICON: UygulamanÄ±n doÄŸrudan metinde aradÄ±ÄŸÄ± teknik beceriler
# - JD_KEYWORDS  : GÃ¶rev/anahtar sÃ¶zcÃ¼kler (pipeline, dashboard vb.) â€” skoru dengeler
# - ALIASES      : YazÄ±m varyasyonlarÄ±nÄ± tekilleÅŸtirme (ms sql -> sql, a/b testing -> ab testing gibi)

SKILL_LEXICON = [
    # Core / DB
    "python","pandas","numpy","sql","postgresql","mysql","sql server","t-sql","ms sql","bigquery",
    # BI & Viz
    "power bi","tableau","looker","google data studio","data visualization","excel","gsheet",
    # ML
    "scikit-learn","machine learning","deep learning","nlp","tensorflow","pytorch",
    "xgboost","random forest","time series","ab testing","a/b testing",
    # Pipelines & DWH
    "etl","ssis","ssas","ssrs","airflow","data modeling","data warehouse",
    # Big Data & Cloud & Tooling
    "spark","hadoop","aws","azure","google cloud","git","github","docker","marketing analytics",
]

JD_KEYWORDS = [
    "dashboard","reporting","pipeline","modeling","deployment","ab testing",
    "segmentation","forecast","recommendation","churn","feature engineering",
    "kpi","optimization","automation","stakeholder","storytelling","experiment",
    "etl","sql","python","power bi","looker","tableau","spark","hadoop","bigquery",
    "airflow","docker","git","time series","marketing analytics"
]

ALIASES = {
    "ms sql":"sql", "mssql":"sql", "sqlserver":"sql", "t sql":"t-sql",
    "google bigquery":"bigquery", "gcp":"google cloud",
    "a b testing":"ab testing", "a/b testing":"ab testing",
}


# ============== 4) YARDIMCI FONKSÄ°YONLAR ==============

# ---- 4.1 Dosya okuyucular ----
def read_pdf(file_bytes: bytes) -> str:
    """PDF dosyasÄ±ndan sayfa sayfa metin Ã§Ä±karÄ±r."""
    reader = PdfReader(io.BytesIO(file_bytes))
    return "\n".join([(p.extract_text() or "") for p in reader.pages])

def read_docx(file_bytes: bytes) -> str:
    """DOCX iÃ§indeki paragraflarÄ± birleÅŸtirir."""
    f = io.BytesIO(file_bytes)
    doc = Document(f)
    return "\n".join([p.text for p in doc.paragraphs])

def read_any(file) -> str:
    """YÃ¼klenen dosyanÄ±n uzantÄ±sÄ±na gÃ¶re uygun okuyucuyu Ã§aÄŸÄ±rÄ±r."""
    name = (file.name or "").lower()
    content = file.read()
    if name.endswith(".pdf"):
        return read_pdf(content)
    if name.endswith(".docx"):
        return read_docx(content)
    # TXT ve diÄŸer durumlar
    return content.decode("utf-8", errors="ignore")


# ---- 4.2 Metin normalizasyonu ----
def _normalize_simple(t: str) -> str:
    """
    Temel normalizasyon:
    - KÃ¼Ã§Ã¼k harfe Ã§evir
    - 's q l' gibi ayrÄ±k yazÄ±mlarÄ± birleÅŸtir
    - 't-sql' varyasyonlarÄ±nÄ± tekilleÅŸtir
    - tire ve noktalama kaldÄ±r, fazla boÅŸluklarÄ± sadeleÅŸtir
    """
    if not t:
        return ""
    t = t.lower()
    t = re.sub(r"s\W*q\W*l", "sql", t)       # s q l -> sql
    t = re.sub(r"t\W*-\W*sql", "t-sql", t)   # t - sql -> t-sql
    t = t.replace("-", " ")
    t = t.translate(str.maketrans("", "", string.punctuation))
    t = re.sub(r"\s+", " ", t).strip()
    return t

def clean_text(t: str) -> str:
    """KullanÄ±m kolaylÄ±ÄŸÄ± iÃ§in tek satÄ±rlÄ±k sarmalayÄ±cÄ±."""
    return _normalize_simple(t)


# ---- 4.3 Skill Ã§Ä±karÄ±mÄ± ----
def extract_skills(text: str) -> list[str]:
    """
    CV/Ä°lan metninden sÃ¶zlÃ¼k bazlÄ± skill Ã§Ä±karÄ±mÄ±.
    1) Metni normalize et
    2) Alias/varyasyonlarÄ± kanonik isimlere Ã§evir
    3) SKILL_LEXICON'daki hedef terimleri ara
    """
    txt = " " + _normalize_simple(text) + " "

    # Metin iÃ§inde alias normalizasyonu yap (Ã¶rn: a/b testing -> ab testing)
    for k, v in ALIASES.items():
        txt = txt.replace(" " + _normalize_simple(k) + " ", " " + _normalize_simple(v) + " ")

    # SÃ¶zlÃ¼k tabanlÄ± tarama
    hits = set()
    for s in SKILL_LEXICON:
        s_norm = " " + _normalize_simple(s) + " "
        if s_norm in txt:
            hits.add(ALIASES.get(_normalize_simple(s), _normalize_simple(s)))  # kanonik isim
    return sorted(hits)


# ---- 4.4 Benzerlik ve skor fonksiyonlarÄ± ----
def tfidf_cosine(a: str, b: str) -> float:
    """TF-IDF + Cosine ile 0â€“1 arasÄ± metin benzerliÄŸi skorunu dÃ¶ndÃ¼rÃ¼r."""
    vect = TfidfVectorizer(ngram_range=(1,2), stop_words="english")
    X = vect.fit_transform([a or "", b or ""])
    return float(cosine_similarity(X[0], X[1])[0,0])

def keyword_overlap_score(cv_text: str, jd_text: str) -> float:
    """
    JD_KEYWORDS listesindeki anahtarlarÄ±n hem CV hem JD'de geÃ§me oranÄ±.
    0â€“1 arasÄ± skor dÃ¶ner (normalize).
    """
    cv_n = " " + _normalize_simple(cv_text) + " "
    jd_n = " " + _normalize_simple(jd_text) + " "
    hits, used = 0, 0
    for kw in JD_KEYWORDS:
        used += 1
        k = " " + _normalize_simple(kw) + " "
        if (k in cv_n) and (k in jd_n):
            hits += 1
    return 0.0 if used == 0 else hits / used

def compute_match_score(cv_text: str, jd_text: str, cv_skills: list[str], jd_skills: list[str]) -> dict:
    """
    Nihai skor (0â€“100) = 0.50*skill_coverage + 0.30*text_sim + 0.20*keyword_overlap
    AyrÄ±ntÄ±lÄ± kÄ±rÄ±lÄ±mÄ± da dÃ¶ndÃ¼rÃ¼r.
    """
    # 1) Skill coverage: JD'de istenen skill'lerin CV'de bulunma oranÄ±
    cov = (len(set(cv_skills) & set(jd_skills)) / max(1, len(jd_skills)))
    # 2) Metin benzerliÄŸi: TF-IDF cosine
    sim = tfidf_cosine(cv_text, jd_text)
    # 3) Anahtar kelime Ã¶rtÃ¼ÅŸmesi
    kw  = keyword_overlap_score(cv_text, jd_text)

    score = (0.50 * cov + 0.30 * sim + 0.20 * kw) * 100
    score = max(0, min(100, round(score)))  # 0â€“100 aralÄ±ÄŸÄ±na sÄ±kÄ±ÅŸtÄ±r

    return {
        "score": score,
        "breakdown": {
            "skill_coverage": round(cov * 100),
            "text_similarity": round(sim * 100),
            "keyword_overlap": round(kw  * 100),
        },
    }


# ---- 4.5 Cover letter Ã¼retimi ----
def make_cover_letter(cv_skills: list[str], gaps: list[str], role: str, company: str,
                      tone: str = "professional", words: int = 220) -> str:
    """
    CV-JD analizine gÃ¶re uzun ve motive edici bir cover letter oluÅŸturur.
    'tone' ve 'words' parametreleri ile stil/uzunluk ayarÄ± yapÄ±labilir.
    """
    strengths = ", ".join((cv_skills or [])[:10]) if cv_skills else "relevant skills"
    soften    = ", ".join((gaps or [])[:6]) if gaps else "no major gaps"

    opening = {
        "professional": f"I am excited to apply for the {role} position at {company}. I combine hands-on analytics with clear communication and an ownership mindset.",
        "friendly":     f"I'm thrilled to apply for the {role} role at {company}! I love turning messy data into useful, human-readable insights."
    }[tone]

    body1 = (
        f"In recent projects, I built end-to-end data workflows using {strengths}. "
        f"I collaborated with cross-functional teams to define KPIs, designed reliable data models, and automated reporting. "
        f"I value clean data practices, reproducible code, and measurable impact."
    )

    body2 = "I learn fast and enjoy tackling ambiguous problems. "
    if gaps and gaps != ["no major gaps"]:
        body2 += f"I'm actively strengthening {soften}, and I approach gaps with a clear learning plan and rapid prototyping."

    closing = (
        f"Thank you for your time and consideration. "
        f"I would welcome the chance to discuss how I can contribute to {company}'s roadmap."
    )

    # Basit kelime sayÄ±sÄ± kontrolÃ¼ (cut-off)
    txt = " ".join([opening, body1, body2, closing]).strip()
    if words and words > 0:
        target = int(words)
        tokens = txt.split()
        if len(tokens) > target:
            txt = " ".join(tokens[:target]) + "..."
    return txt


# ============== 5) ARAYÃœZ (UI) ==============

# ---- 5.1 Dosya yÃ¼kleme alanlarÄ± ----
col1, col2 = st.columns(2)
with col1:
    cv_file = st.file_uploader("CV yÃ¼kle (PDF/DOCX/TXT)", type=["pdf","docx","txt"], key="cv")
with col2:
    jd_file = st.file_uploader("Ä°ÅŸ ilanÄ± yÃ¼kle (PDF/DOCX/TXT)", type=["pdf","docx","txt"], key="jd")

# ---- 5.2 KullanÄ±cÄ± ayarlarÄ± ----
role    = st.text_input("Pozisyon baÅŸlÄ±ÄŸÄ±", value="Data Scientist")
company = st.text_input("Åirket adÄ±", value="Your Company")
tone    = st.selectbox("Cover letter tonu", ["professional","friendly"], index=0)
words   = st.slider("Cover letter uzunluÄŸu (kelime)", 120, 300, 220, 10)

# ---- 5.3 Hesapla butonu ----
if st.button("EÅŸleÅŸmeyi Hesapla", type="primary"):

    # 1) Dosya kontrolÃ¼
    if not (cv_file and jd_file):
        st.warning("LÃ¼tfen hem CV hem de iÅŸ ilanÄ± dosyasÄ±nÄ± yÃ¼kleyin.")
        st.stop()

    # 2) Metinleri oku + normalize et
    cv_text = clean_text(read_any(cv_file))
    jd_text = clean_text(read_any(jd_file))

    # 3) Skill Ã§Ä±karÄ±mÄ±
    cv_skills = extract_skills(cv_text)
    jd_skills = extract_skills(jd_text)

    # 4) Skor hesapla + gÃ¼Ã§lÃ¼ / geliÅŸtirilmesi gereken alanlar
    result     = compute_match_score(cv_text, jd_text, cv_skills, jd_skills)
    strengths  = sorted(set(cv_skills) & set(jd_skills))
    gaps       = sorted(set(jd_skills) - set(cv_skills))

    # 5) SonuÃ§lar
    st.metric("EÅŸleÅŸme Skoru", f"{result['score']}/100")
    st.caption(
        f"ğŸ§® KÄ±rÄ±lÄ±m â†’ Skills: {result['breakdown']['skill_coverage']} | "
        f"TF-IDF: {result['breakdown']['text_similarity']} | "
        f"Keywords: {result['breakdown']['keyword_overlap']}"
    )

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**GÃ¼Ã§lÃ¼ YÃ¶nler (Skill EÅŸleÅŸmeleri)**")
        st.write(strengths or "â€”")
    with c2:
        st.markdown("**GeliÅŸtirilecek Alanlar (JDâ€™de var, CVâ€™de yok)**")
        st.write(gaps or "â€”")

    # (Ä°steÄŸe baÄŸlÄ± debug Ã§Ä±ktÄ±sÄ±)
    # st.caption(f"cv_skills: {cv_skills}")
    # st.caption(f"jd_skills: {jd_skills}")

    # 6) Cover Letter
    st.subheader("âœ‰ï¸ Cover Letter TaslaÄŸÄ±")
    letter = make_cover_letter(strengths or cv_skills, gaps, role or "the role", company or "your company",
                               tone=tone, words=words)
    st.write(letter)
